<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta name="google-site-verification" content="jkuH3aDxiNM_Pid88-6qOVKI254b9C95ZwPB2JPSKGU" />
<meta name="baidu-site-verification" content="BS8e1euy0f" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Songbo's Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Songbo's Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Songbo's Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> Songbo's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Songbo's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/26/impala-in-gridsum-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Songbo Liao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Songbo's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/26/impala-in-gridsum-1/" itemprop="url">
                  Impala在国双的使用（一）：Impala架构和概念介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-26T21:45:44+08:00">
                2017-10-26
              </time>
            

            

            
          </span>

          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/10/26/impala-in-gridsum-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2017/10/26/impala-in-gridsum-1/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          
             <span id="/2017/10/26/impala-in-gridsum-1/" class="leancloud_visitors" data-flag-title="Impala在国双的使用（一）：Impala架构和概念介绍">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><a href="#impala是什么">Impala是什么</a></li>
<li><a href="#为什么国双采用impala">为什么国双采用Impala</a></li>
<li><a href="#Impala架构">Impala架构</a><ul>
<li><a href="#impalad">Impalad</a></li>
<li><a href="#catalogd">Catalogd</a></li>
<li><a href="#statestored">Statestored</a></li>
</ul>
</li>
<li><a href="#impala的资源池">Impala的资源池</a><ul>
<li><a href="#memory-limit">Memory Limit</a></li>
<li><a href="#软隔离">软隔离</a></li>
</ul>
</li>
</ul>
<h2 id="impala是什么"><a href="#Impala是什么" class="headerlink" title="Impala是什么"></a>Impala是什么</h2><p>Cloudera Impala是一个分布式的海量关系型数据查询引擎，有以下特点：</p>
<ul>
<li>低延时，非常适合交互式查询的场景。我们和Hive on Tez, Azure SQL Data Warehouse做过查询性能对比，Impala的性能优势非常明显。</li>
<li>Impala和Hive共享元数据和存储数据，使得Hive和SparkSQL生成的数据可以在Impala里刷新后直接查询，这一点非常重要，因为目前业内广泛采用Hive和SparkSQL做数据的ETL，ETL后数据只要简单刷新就可以在Impala里做交互式查询，为网站，APP等客户端直接提供及时的数据服务。</li>
<li>构建在Hive和HDFS的基础之上，由于Hive和HDFS都是业内久经考验的成熟技术，基本不会出现数据丢失或者集群彻底挂掉的情况。Hive和HDFS网上信息非常多，很多Impala问题可以从Hive和HDFS的角度来解决，降低了排查和解决问题的成本。</li>
<li>可扩展性强，扩展成本低：其他分布式数据库例如GreenPlum在可扩展性上有很多问题，根据 <a href="https://gpdb.docs.pivotal.io/500/admin_guide/expand/expand-redistribute.html" target="_blank" rel="external">https://gpdb.docs.pivotal.io/500/admin_guide/expand/expand-redistribute.html</a> GreenPlum在加节点后需要手动Redistributing来把老数据搬运到新节点上，在Redistributing期间对集群整体性能有较大影响，而且正在Redistributing的Table或者分区会被锁上无法访问。而Impala只要加HDFS和Impala节点就可以完成扩容，HDFS Balancer会负责数据缓慢迁移，而扩容期间查询性能几乎不会受任何影响。</li>
</ul>
<h2 id="为什么国双采用impala"><a href="#为什么国双采用Impala" class="headerlink" title="为什么国双采用Impala"></a>为什么国双采用Impala</h2><p>作为国内第一家在纳斯达克上市的大数据公司，国双每天处理和查询的数据量级非常大，所以我们采用了业界比较通用的Spark和Hive进行数据ETL，每天无论是国双的咨询师还是外部客户都需要在海量数据中第一时间得到有用的信息，而Cloudera Impala提供了这一能力。</p>
<h2 id="impala架构"><a href="#Impala架构" class="headerlink" title="Impala架构"></a>Impala架构</h2><p>官网上对Impala的架构和组件有一些介绍：<a href="https://www.cloudera.com/documentation/enterprise/5-8-x/topics/impala_components.html#intro_components" target="_blank" rel="external">https://www.cloudera.com/documentation/enterprise/5-8-x/topics/impala_components.html#intro_components</a> 但说的并不非常清晰 。Impala由三大组件构成：</p>
<p><img src="/2017/10/26/impala-in-gridsum-1/impala_components.png" alt=""></p>
<h3 id="impalad"><a href="#Impalad" class="headerlink" title="Impalad"></a>Impalad</h3><p>基本是每个DataNode上都会启动一个Impalad进程，Impalad主要扮演两个角色：</p>
<ul>
<li>Coordinator：<ul>
<li>负责接收客户端发来的查询，解析查询，构建查询计划</li>
<li>把查询子任务分发给很多Executor</li>
<li>收集Executor返回的结果，组合后返回给客户端</li>
<li>对于客户端发送来的DDL，提交给Catalogd处理</li>
</ul>
</li>
<li>Executor：<ul>
<li>执行查询子任务，将子任务结果返回给Coordinator</li>
</ul>
</li>
</ul>
<p>在Impala2.9中增加了新的Feature：is_executor and is_coordinator 。可以指定一个Impalad只作为Executor或者Coordinator。可以减轻Coordinator的负担，而且让职责单一化。</p>
<h3 id="catalogd"><a href="#Catalogd" class="headerlink" title="Catalogd"></a>Catalogd</h3><p>整个集群只有一个Catalogd，负责所有元数据的更新和获取。每个Impalad本地会缓存元数据信息。在Impala集群中Catalogd主要处理DDL，和Hive MetaStore通信，在Hive MetaStore里更新表的Schema。在Impala集群中Catalogd可以算是一大瓶颈，所以Impala本身不是一个很好的ETL工具，不适合承载大量的DDL操作。如果业务上允许最好是可以在Hive来做DDL，Impala只是做查询引擎。这个系列后续文章会仔细分析Catalogd的问题。</p>
<h3 id="statestored"><a href="#Statestored" class="headerlink" title="Statestored"></a>Statestored</h3><p>整个集群只有一个Statestored，作为集群的订阅中心，负责集群不同组件的信息同步。所谓订阅如下图：</p>
<p><img src="/2017/10/26/impala-in-gridsum-1/impala_subscription.png" alt=""></p>
<p>如上图所示各组件会在StateStored里订阅某个Topic，例如组件1，组件2，组件3订阅了Topic_1。于是StateStored会定期给组件1、组件2、组件3发送心跳，心跳的内容就是这个Topic的数据。订阅者例如组件1可以更新数据然后作为心跳的Response返回给StateStored，这样在下一次StateStored发送给组件2、组件3的心跳里就包含了组件1对于Topic_1的更新。上图中组件2同时订阅了两个Topic，StateStored会把两个Topic的数据通过过一次心跳发给组件2，不会发送两次。  </p>
<p>目前已知的Topic有：</p>
<ul>
<li>impala-membership ：负责全局广播每个Impalad节点的进程健康状态，各Impalad都订阅了这个Topic，所以StateStored会定期发送这个Topic的心跳，广播所有节点的健康信息，也从心跳的Response得到所有节点的健康状态。</li>
<li>catalog-update：负责广播元数据的更新，Catalogd和各Impalad都订阅了这个Topic。所以StateStored会定期发送这个Topic的心跳，Catalogd收到这个心跳后会在Response里放入更新的表元数据，StateStored收到更新后会放入下一次广播的心跳里，Impalad收到心跳后会用更新的元数据更新本地的元数据信息。</li>
<li>impala-request-queue：负责广播每个Pool占用和Queue的情况，各Impalad都订阅了这个Topic，关于Pool和Queue下面一节会有详细的描述。</li>
</ul>
<blockquote>
<blockquote>
<p>如果大家去看其他一些类似的分布式数据库例如Facebook的Presto，会发现其组件结构和Impala是非常类似的，虽然名字略有不同。</p>
</blockquote>
</blockquote>
<h2 id="impala的资源池"><a href="#Impala的资源池" class="headerlink" title="Impala的资源池"></a>Impala的资源池</h2><p>Impala可以划分很多资源池（Pool），用来对不同业务做资源隔离，对于一个Impala查询来说，用户可以设置使用哪个Pool，如果不设置，默认使用Default Pool。每个Pool有以下设置：</p>
<ul>
<li>最大内存：Pool里的所用查询能用的总内存上限</li>
<li>最大运行查询数量：Pool里可以同时运行的最大查询数量</li>
<li>Queue的长度：查询可能因为最大内存，最大运行数量等限制被Queue住。如果Queue长度已经到达这个上限，查询会被直接拒绝。</li>
<li>Queue Timeout：查询在Queue里等待的时间，超过这个时间查询会被报错返回。</li>
<li>Default Query Memory Limit</li>
</ul>
<h3 id="memory-limit"><a href="#Memory-Limit" class="headerlink" title="Memory Limit"></a>Memory Limit</h3><p>对于一个Impala查询来说，用户可以设置 Memory Limit（mem_limit参数），就是这个查询在单个Impalad节点上能用到的内存上限，如果查询在某个节点超过了这个上限会被直接报错返回。如果用户不设置，默认使用Pool的Default Query Memory Limit，如果Pool没有设置，Impala会自己来估计这个值。据我们的使用经验来说，Impala自己估计的值非常不准确（如果表有统计信息会好一些，但还是很不准）。所以建议用户根据查询大小和复杂程度设置这个值。</p>
<p>mem_limit参数对查询的影响很大，例如一个查询set mem_limit = 10G，有30台Impalad节点，Impala就会认为这个查询会用到10G * 30 = 300G内存。如果Pool的剩余内存目前小于300G，查询就会被Queue住等待资源。所以mem_limit如果设置的太大会浪费内存，导致并发度降低；如果设置的太小会导致查询失败。这个系列后面会有一篇文章来说国双是如何通过机器学习的方式来解决这个问题的。</p>
<h3 id="软隔离"><a href="#软隔离" class="headerlink" title="软隔离"></a>软隔离</h3><p>由于Impala的每个Impalad节点都可以接受查询，对于每个Pool现在有多少查询，占了多少内存，Queue了多少，这些信息也是每个Impalad更新，通过Statestored来广播到其他Impalad，所以这个信息可能在每个节点上可能是不一致的。当一个Impalad收到查询需要做一些决策例如是否拒绝，是否Queue住，本地的这个决策信息可能是旧的，所以Impala基于Pool的资源隔离本身来说是一种软隔离，也就是说对于任何一个Pool来说，其用到的内存有可能会超过最大内存，运行的查询数量有可能会超过Pool设置的最大查询数量。这个我们在实际的使用中也证明了。软隔离问题会带来两个风险：</p>
<ol>
<li>单个节点申请的内存在某个时刻超过了分配给Impalad进程的内存，这个会导致Impalad OOM退出</li>
<li>某个Pool在某一个时刻使用了远远超过这个Pool的资源，这个对于不同业务用Pool来做资源隔离是不利的。</li>
</ol>
<p>这个问题我们也跟Impala社区的开发者做过讨论，最后使用的方案是：<strong>单个Pool指定唯一的Coordinator</strong>，这个Pool的所有查询都发送给同一个Impalad。于是这个Coordinator时刻都有这个资源池最新的信息，就从软隔离进化成了硬隔离，缺点是会带来单点问题，我们也采取了主备的方式来避免这一问题，后续的文章会进一步说明。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/09/select-vs-epoll/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Songbo Liao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Songbo's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/09/select-vs-epoll/" itemprop="url">
                  select vs epoll
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-09T15:43:39+08:00">
                2017-04-09
              </time>
            

            

            
          </span>

          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/04/09/select-vs-epoll/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2017/04/09/select-vs-epoll/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          
             <span id="/2017/04/09/select-vs-epoll/" class="leancloud_visitors" data-flag-title="select vs epoll">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在 <a href="http://songboisgood.github.io/2017/04/01/client-server-socket/" target="_blank" rel="external">http://songboisgood.github.io/2017/04/01/client-server-socket/</a> 里，我们已经介绍了client和server如何通信。但一般来说，一个Web Server需要处理很多请求，从网上抄了个最简单的例子如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line">int main() &#123;</div><div class="line">	int server_fd, client_fd;</div><div class="line">	struct sockaddr_in server_addr;</div><div class="line">	struct sockaddr_in client_addr;</div><div class="line">	int sin_size;</div><div class="line">	char buff[100];</div><div class="line">	int numbytes;</div><div class="line"></div><div class="line">	//建立TCP套接口</div><div class="line">	if((server_fd = socket(AF_INET,SOCK_STREAM,0))==-1) &#123;</div><div class="line">		perror(&quot;socket&quot;);</div><div class="line">		exit(1);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	//初始化结构体，并绑定2323端口</div><div class="line">	server_addr.sin_family = AF_INET;</div><div class="line">	server_addr.sin_port = htons(2323);</div><div class="line">	server_addr.sin_addr.s_addr = INADDR_ANY;</div><div class="line">	bzero(&amp;(server_addr.sin_zero),8);</div><div class="line"></div><div class="line">	if(bind(server_fd,(struct sockaddr *)&amp;server_addr,sizeof(struct sockaddr))==-1)</div><div class="line">	&#123;</div><div class="line">		perror(&quot;bind&quot;);</div><div class="line">		exit(1);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	//监听套接口</div><div class="line">	if(listen(server_fd,10)==-1) &#123;</div><div class="line">		perror(&quot;listen&quot;);</div><div class="line">		exit(1);</div><div class="line">	&#125;</div><div class="line">	printf(&quot;server is run.../n&quot;);</div><div class="line"></div><div class="line">	//等待连接</div><div class="line">	while(1) &#123;</div><div class="line">		sin_size = sizeof(struct sockaddr_in);</div><div class="line"></div><div class="line">		//如果建立连接，将产生一个全新的套接字</div><div class="line">		if((client_fd = accept(server_fd,(struct sockaddr *)&amp;client_addr,&amp;sin_size))==-1)</div><div class="line">		&#123;</div><div class="line">			perror(&quot;accept&quot;);</div><div class="line">			exit(1);</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		//读取客户端发来的信息</div><div class="line">		if((numbytes = recv(client_fd,buff,sizeof(buff),0))==-1)</div><div class="line">		&#123;</div><div class="line">			perror(&quot;recv&quot;);</div><div class="line">			exit(1);</div><div class="line">		&#125;</div><div class="line">		buff[numbytes]=&apos;/0&apos;;</div><div class="line"></div><div class="line">		//将从客户端接收到的信息再发回客户端</div><div class="line">		if(send(client_fd,buff,strlen(buff),0)==-1)</div><div class="line">			perror(&quot;send&quot;);</div><div class="line">			close(new_fd);</div><div class="line">			exit(0);</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		close(client_fd);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	close(server_fd);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上面的流程有什么问题呢？问题在于很多函数例如accept，recv，write都是阻塞的，而web server必须有同时处理很多请求的能力，不能在一个请求阻塞的时候就不处理其他请求了。</p>
<p>一般的做法是accept之后把client的socket交由一个单独的线程/进程来继续处理，然后主线程继续循环accept。这样的问题是线程/进程创建有开销，再好的线程池也没法handle太多线程（C10K问题 <a href="http://www.kegel.com/c10k.html）" target="_blank" rel="external">http://www.kegel.com/c10k.html）</a><br>所以像Nginx， Tornado这些Web Server就使用异步的方式来处理请求，利用操作系统的select， epoll等方法构造一个无阻塞的Web Server。</p>
<h2 id="select函数"><a href="#select函数" class="headerlink" title="select函数"></a>select函数</h2><p>对于Web Server来说，阻塞一般源于 socket is not ready: 例如内核的输出buffer满了，所以write函数阻塞；内核的ACCEPT队列为空，所以accept函数阻塞。</p>
<p>select函数可以知道哪些socket is ready，这样我们在每次循环里只要处理ready 的socket就可以了，不ready的就等下次循环再说。</p>
<h3 id="select-定义"><a href="#select-定义" class="headerlink" title="select 定义"></a>select 定义</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);</div></pre></td></tr></table></figure>
<ul>
<li>nfds：select监视的文件句柄数</li>
<li>readfds：select监视的可读文件句柄集合。</li>
<li>writefds: select监视的可写文件句柄集合。</li>
<li>exceptfds：select监视的异常文件句柄集合。</li>
<li>timeout：本次select()的超时结束时间</li>
</ul>
<h3 id="select的使用"><a href="#select的使用" class="headerlink" title="select的使用"></a>select的使用</h3><ul>
<li>新建readset, writeset, exset， 类型都是fd_set，都可以看做是socket的列表</li>
<li>在while循环里:<ul>
<li>首先用FD_SET函数把sockfd放到read_set里</li>
<li>用select函数等待readset和writeset里有fd ready:</li>
<li>对readset里有fd ready且是server_fd，调用accept函数，得到client_fd，然后用FD_SET函数加到read_set里</li>
<li>对readset里有fd ready且不是server_fd，调用recv函数。如果是读完了就把client_fd用FD_SET函数加到writeset里</li>
<li>对writeset里有fd ready，调用write函数。</li>
</ul>
</li>
</ul>
<p>使用了select函数，无论是有新的连接（server_fd is ready），还是有读写阻塞被唤醒（client_fd is ready），都会唤醒select函数并一一处理。这就是一个non-blocking Web Server的雏形。</p>
<h3 id="select实现"><a href="#select实现" class="headerlink" title="select实现"></a>select实现</h3><blockquote>
<blockquote>
<blockquote>
<p> Linux执行路径：sys_select -&gt; core_sys_select -&gt; do_select</p>
</blockquote>
</blockquote>
</blockquote>
<p>sys_select.cpp</p>
<ol>
<li>处理超时</li>
<li>调用 core_sys_select</li>
</ol>
<p>core_sys_select.cpp</p>
<ol>
<li>把所有fd从用户态copy到内核态</li>
<li>调用 do_select</li>
<li>把符合条件的fd从内核态copy回用户态</li>
</ol>
<p>do_select.cpp</p>
<ol>
<li>遍历所有fd，看是否有ready的</li>
<li>返回符合条件的fd</li>
</ol>
<h3 id="select的几大缺点"><a href="#select的几大缺点" class="headerlink" title="select的几大缺点"></a>select的几大缺点</h3><ul>
<li>每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大</li>
<li>同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大</li>
<li>select支持的文件描述符数量太小了，默认是1024</li>
</ul>
<h2 id="epoll函数"><a href="#epoll函数" class="headerlink" title="epoll函数"></a>epoll函数</h2><h3 id="epoll定义"><a href="#epoll定义" class="headerlink" title="epoll定义"></a>epoll定义</h3><p>epoll操作过程需要三个接口，分别如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#include &lt;sys/epoll.h&gt;</div><div class="line">int epoll_create(int size);</div><div class="line">int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);</div><div class="line">int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</div></pre></td></tr></table></figure></p>
<h3 id="int-epoll_createint-size"><a href="#int-epoll-create-int-size" class="headerlink" title="int epoll_create(int size)"></a>int epoll_create(int size)</h3><ul>
<li>创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，Linux 2.6以后用红黑树保存，这个参数就没用了。需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。</li>
<li>在内核Cache里创建了一颗红黑树，用来保存以后进来的fd</li>
<li>在内核Cache创建了一个就绪列表</li>
</ul>
<h3 id="int-epoll_ctlint-epfd-int-op-int-fd-struct-epoll_event-event"><a href="#int-epoll-ctl-int-epfd-int-op-int-fd-struct-epoll-event-event" class="headerlink" title="int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)"></a>int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)</h3><blockquote>
<blockquote>
<p>epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件,而是在这里先注册要监听的事件类型。</p>
</blockquote>
</blockquote>
<ul>
<li>epfd 是epoll_create()的返回值</li>
<li><p>op表示动作，用三个宏来表示：</p>
<ul>
<li>EPOLL_CTL_ADD：注册新的fd到epfd中；真实做法是<ul>
<li>将fd插入到红黑树中，如果原来已经存在返回-EEXIST，</li>
<li>给fd注册一个回调函数，该函数会在fd有事件时调用，在该函数中将fd加入到epoll的就绪队列中。</li>
<li>检查fd当前是否已经有期望的事件产生。如果有，将其加入到epoll的就绪列表中，唤醒epoll_wait。</li>
</ul>
</li>
<li>EPOLL_CTL_MOD：修改已经注册的fd的监听事件；做法是<ul>
<li>在红黑树中用新的事件替换旧的事件</li>
<li>检查fd是否有期望的事件。如果有，将其加入到epoll的就绪列表中，唤醒epoll_wait</li>
</ul>
</li>
<li>EPOLL_CTL_DEL：从epfd中删除一个fd；做法是：<ul>
<li>将fd从红黑树里删除</li>
</ul>
</li>
</ul>
</li>
<li><p>第三个参数fd是需要监听的fd，第四个参数event是告诉内核需要监听什么事，struct epoll_event结构如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">struct epoll_event &#123;</div><div class="line">  __uint32_t events;  /* Epoll events */</div><div class="line">  epoll_data_t data;  /* User data variable */</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>events可以是以下几个宏的集合：<br>EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；<br>EPOLLOUT：表示对应的文件描述符可以写；<br>EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；<br>EPOLLERR：表示对应的文件描述符发生错误；<br>EPOLLHUP：表示对应的文件描述符被挂断；<br>EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。<br>EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里</p>
<h3 id="int-epoll_waitint-epfd-struct-epoll_event-events-int-maxevents-int-timeout"><a href="#int-epoll-wait-int-epfd-struct-epoll-event-events-int-maxevents-int-timeout" class="headerlink" title="int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout)"></a>int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout)</h3><blockquote>
<blockquote>
<p>这个函数用来等待事件的产生，类似于select()调用。</p>
</blockquote>
</blockquote>
<ul>
<li>参数：<ul>
<li>events用来从内核得到事件的集合</li>
<li>maxevents告之内核最多能返回多少个events（代表外部一次处理能力），这个maxevents的值不能大于创建epoll_create()时的size。</li>
<li>参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。</li>
</ul>
</li>
<li>做法：<ul>
<li>如果epoll的就绪列表为空，并且timeout非0，挂起当前进程，引起CPU调度。</li>
<li>如果epoll的就绪列表不空，遍历就绪队列。对队列中的每一个节点，获取该文件已触发的事件，判断其中是否有我们期待的事件，如果有，将其对应的epoll_event结构copy到用户events。</li>
</ul>
</li>
</ul>
<h2 id="epoll-为什么比select高效"><a href="#epoll-为什么比select高效" class="headerlink" title="epoll 为什么比select高效?"></a>epoll 为什么比select高效?</h2><ul>
<li>每次循环里的select每次调用都要将fd列表从用户态拷贝到内核态，当fd数目很多时，这会造成低效。而每次调用epoll_wait时（作用相当于调用select），不需要再传递fd列表给内核，因为fd已经缓存在内核的红黑树里了。而每次epoll_ctl也只是对这个红黑树增删改而已。</li>
<li>由于在内核Cache里有<strong>就绪列表</strong>，每次epoll_wait时，只需要扫描就绪列表就可以，不用扫描所有的fd了</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/01/client-server-socket/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Songbo Liao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Songbo's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/01/client-server-socket/" itemprop="url">
                  最简单的Client Server TCP通信介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-01T21:09:36+08:00">
                2017-04-01
              </time>
            

            

            
          </span>

          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/04/01/client-server-socket/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2017/04/01/client-server-socket/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          
             <span id="/2017/04/01/client-server-socket/" class="leancloud_visitors" data-flag-title="最简单的Client Server TCP通信介绍">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="client-server-tcp-通信图"><a href="#Client-Server-TCP-通信图" class="headerlink" title="Client Server TCP 通信图"></a>Client Server TCP 通信图</h2><p><img src="/2017/04/01/client-server-socket/client_server.png" alt=""></p>
<h2 id="server端"><a href="#Server端" class="headerlink" title="Server端"></a>Server端</h2><p>S1. socket函数： 创建一个socket<br>S2. bind函数： 把socket和一个地址绑定，地址可以是IPV4，IPV6或者UNIX Domain地址<br>S3. listen函数： 监听这个socket<br>S4. accept/accept4函数：阻塞等待Client的connect。<br>S5. recv/recvfrom/recvmsg/read函数: 从Client接收数据。<br>S6. send/sendto/sendmsg/write函数：给Client发送数据。</p>
<h2 id="client端"><a href="#Client端" class="headerlink" title="Client端"></a>Client端</h2><p>C1. socket函数： 创建一个socket。<br>C2. connect函数：连接 Server<br>C3. send/sendto/sendmsg/write函数 : 向 Server 发消息<br>C4. recv/recvfrom/recvmsg/read函数: 从Server读取数据<br>C5. close函数：close这个socket</p>
<h2 id="函数解释"><a href="#函数解释" class="headerlink" title="函数解释"></a>函数解释</h2><h3 id="socket函数"><a href="#socket函数" class="headerlink" title="socket函数"></a>socket函数</h3><blockquote>
<blockquote>
<p>int socket(int domain, int type, int protocol);</p>
</blockquote>
</blockquote>
<p>创建一个socket。socket默认是blocking的，可以用fcntl设置成non-blocking，如果是non-blocking，对这个socket accept或者recv时没有ready就直接报错。</p>
<ul>
<li>domain : 又称为协议族（family）。常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）等等。<ul>
<li>AF_INET代表IPV4: <a href="https://msdn.microsoft.com/en-us/library/windows/hardware/ff543744(v=vs.85).aspx" target="_blank" rel="external">https://msdn.microsoft.com/en-us/library/windows/hardware/ff543744(v=vs.85).aspx</a></li>
<li>AF_INET6代表IPV6：<a href="https://msdn.microsoft.com/en-us/library/windows/hardware/ff543746(v=vs.85).aspx" target="_blank" rel="external">https://msdn.microsoft.com/en-us/library/windows/hardware/ff543746(v=vs.85).aspx</a></li>
<li>AF_UNIX代表UNIX Domain Socket IPC，主要用于进程间通信：<a href="https://akaedu.github.io/book/ch37s04.html" target="_blank" rel="external">https://akaedu.github.io/book/ch37s04.html</a></li>
</ul>
</li>
<li>type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW等<ul>
<li>SOCK_STREAM 代表TCP</li>
<li>SOCK_DGRAM 代表UDP</li>
<li>SOCK_RAW 工作在传输层，用于处理ICMP、IGMP等网络报文以及特殊协议报文</li>
</ul>
</li>
<li>protocol：就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议</li>
<li>返回值是一个file descriptor (sockfd)  that refers to that socket</li>
</ul>
<h3 id="bind函数"><a href="#bind函数" class="headerlink" title="bind函数"></a>bind函数</h3><blockquote>
<blockquote>
<p>int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen)</p>
</blockquote>
</blockquote>
<p>把socket和一个地址绑定，地址可以是IPV4，IPV6或者UNIX Domain地址</p>
<ul>
<li>sockfd：之前socket函数返回的sockfd</li>
<li><p>sockaddr： 地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">// IPV4地址</div><div class="line">struct sockaddr_in &#123;</div><div class="line">    sa_family_t    sin_family; /* address family: AF_INET */</div><div class="line">    in_port_t      sin_port;   /* port in network byte order */</div><div class="line">    struct in_addr sin_addr;   /* internet address */</div><div class="line">&#125;;</div><div class="line">// IPV6地址</div><div class="line">struct sockaddr_in6 &#123;</div><div class="line">    sa_family_t     sin6_family;   /* AF_INET6 */</div><div class="line">    in_port_t       sin6_port;     /* port number */</div><div class="line">    uint32_t        sin6_flowinfo; /* IPv6 flow information */</div><div class="line">    struct in6_addr sin6_addr;     /* IPv6 address */</div><div class="line">    uint32_t        sin6_scope_id; /* Scope ID (new in 2.4) */</div><div class="line">&#125;;</div><div class="line">// UNIX Domain地址</div><div class="line">#define UNIX_PATH_MAX    108</div><div class="line"></div><div class="line">struct sockaddr_un &#123;</div><div class="line">    sa_family_t sun_family;               /* AF_UNIX */</div><div class="line">    char        sun_path[UNIX_PATH_MAX];  /* pathname */</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
<li><p>addrlen：地址长度</p>
</li>
<li>返回：成功返回0，错误返回-1</li>
</ul>
<h2 id="listen函数"><a href="#listen函数" class="headerlink" title="listen函数"></a>listen函数</h2><blockquote>
<blockquote>
<p>int listen(int sockfd, int backlog)</p>
</blockquote>
</blockquote>
<p>监听一个socket，listen一般不会Block，内核会建立两个队列，SYN队列和ACCEPT队列，其中ACCPET队列的长度由backlog指定。</p>
<ul>
<li>sockfd：监听的socket</li>
<li>backlog：ACCPET队列的长度</li>
<li>返回：成功返回0，错误返回-1</li>
</ul>
<h3 id="accept函数"><a href="#accept函数" class="headerlink" title="accept函数"></a>accept函数</h3><blockquote>
<blockquote>
<p>int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen)<br>int accept4(int sockfd, struct sockaddr <em>addr, socklen_t </em>addrlen, int flags);</p>
</blockquote>
</blockquote>
<p>accpet函数将阻塞，等待ACCPT队列有元素。就是等待Client的connect来唤醒，建立一个Client的Socket并且返回。</p>
<ul>
<li>sockfd ：Server之前创建的socket的fd</li>
<li>sockaddr：用于保存客户端的地址</li>
<li>addrlen：用于保存客户端地址的长度</li>
<li>flags：accept4比accept多出来的一个参数。flags = 0 时 accept4和accept没区别，flags=SOCK_NONBLOCK等于直接设置客户端socket为NONBLOCK；flags=SOCK_CLOEXEC等于直接设置客户端socket为FD_CLOEXEC，使得进程在fork或者execve时自动关闭socket。</li>
<li>返回 客户端socket的fd</li>
</ul>
<h3 id="connect函数"><a href="#connect函数" class="headerlink" title="connect函数"></a>connect函数</h3><blockquote>
<blockquote>
<p>int connect(int sockfd, const struct sockaddr *addr,  socklen_t addrlen);</p>
</blockquote>
</blockquote>
<p>连接server，是一个block函数</p>
<ul>
<li>sockfd：Client的socket fd</li>
<li>addr：Server的地址</li>
<li>addrlen：Server的地址的长度</li>
<li>返回：成功返回0，错误返回-1</li>
<li>详细做法：<ul>
<li>发起SYN请求，请求与Server建立连接，此时称为第一次握手</li>
<li>Server（listen之后） 在接受到SYN请求之后，把请求方放入SYN队列中，并给Client回复一个确认帧ACK，此帧还会携带一个请求与Client建立连接的请求标志，也就是SYN，这称为第二次握手</li>
<li>Client收到SYN+ACK帧后，connect返回，并发送确认建立连接帧ACK给Server。这称为第三次握手</li>
<li>Server收到ACK帧后，会把请求方从SYN队列中移出，放至ACCEPT队列中，而accept函数也等到了自己的资源，从阻塞中唤醒</li>
</ul>
</li>
</ul>
<h3 id="recvrecvfromrecvmsgread函数"><a href="#recv-recvfrom-recvmsg-read函数" class="headerlink" title="recv/recvfrom/recvmsg/read函数"></a>recv/recvfrom/recvmsg/read函数</h3><blockquote>
<blockquote>
<p>ssize_t recv(int sockfd, void <em>buf, size_t len, int flags)<br>ssize_t recvfrom(int sockfd, void </em>buf, size_t len, int flags, struct sockaddr <em>src_addr, socklen_t </em>addrlen);<br>ssize_t recvmsg(int socket, struct msghdr <em>message, int flags);<br>ssize_t read(int fd, void </em>buf, size_t count);</p>
</blockquote>
</blockquote>
<p>从kernel中的TCP接收缓冲区里读取数据</p>
<ul>
<li>recv vs read : recv比read多一个flag参数用来控制<ul>
<li>数据在不超过指定的长度的时候read会有多少读多少，没有数据则会一直等待。所以一般情况下：我们读取数据都需要采用循环读的方式读取数据，因为一次read 完毕不能保证读到我们需要长度的数据，read 完一次需要判断读到的数据长度再决定是否还需要再次读取。</li>
<li>recv比read多一个flag参数用来控制，flag = MSG_WAITALLs时下recv 是会等待直到读取到buff_size 长度的数据。flag = MSG_PEEK,表示只是从系统缓冲区中读取内容,而不清除系统缓冲区的内容.这样下次读的时候,仍然是一样的内容.一般在有多个进程读写数据时可以使用这个标志.</li>
</ul>
</li>
<li>recv vs recvfrom vs recvmsg : recv主要是针对有连接的情况（TCP），recvfrom和recvmsg 既可以读有连接的，也可以读无连接的（UDP）</li>
</ul>
<h2 id="sendsendtosendmsgwrite-函数"><a href="#send-sendto-sendmsg-write-函数" class="headerlink" title="send/sendto/sendmsg/write 函数"></a>send/sendto/sendmsg/write 函数</h2><blockquote>
<blockquote>
<p>ssize_t send(int sockfd, const void <em>buf, size_t len, int flags);<br>ssize_t write(int fd, const void </em>buf, size_t count)<br>ssize_t sendto(int sockfd, const void <em>buf, size_t len, int flags, const struct sockaddr </em>dest_addr, socklen_t addrlen);<br>ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);</p>
</blockquote>
</blockquote>
<p>write成功返回，只是buf中的数据被复制到了kernel中的TCP发送缓冲区。当kernel的该socket的发送缓冲区已满时，<strong>write会阻塞</strong>。对于每个socket，拥有自己的send buffer和receive buffer。从Linux 2.6开始，两个缓冲区大小都由系统来自动调节（autotuning），但一般在default和max之间浮动。 已经发送到网络的数据依然需要暂存在send buffer中，只有收到对方的ack后，kernel才从buffer中清除这一部分数据，为后续发送数据腾出空间。一般来说，由于接收端进程从socket读数据的速度跟不上发送端进程向socket写数据的速度，最终导致发送端write调用阻塞。</p>
<ul>
<li>send vs write ：send比write多一个flag参数用来控制<ul>
<li>flags参数：<a href="https://linux.die.net/man/2/send" target="_blank" rel="external">https://linux.die.net/man/2/send</a></li>
</ul>
</li>
<li>send vs sendto vs sendmsg：send主要是针对有连接的情况（TCP），sendto 和  sendmsg既可以写有连接的，也可以写无连接的（UDP）</li>
</ul>
<h2 id="closeshutdown函数"><a href="#close-shutdown函数" class="headerlink" title="close/shutdown函数"></a>close/shutdown函数</h2><blockquote>
<blockquote>
<p>int close(sockfd);<br>int shutdown(int sockfd, int how);</p>
</blockquote>
</blockquote>
<p>区别：<a href="http://beej.us/guide/bgnet/output/html/singlepage/bgnet.html#closedown" target="_blank" rel="external">http://beej.us/guide/bgnet/output/html/singlepage/bgnet.html#closedown</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Songbo Liao" />
          <p class="site-author-name" itemprop="name">Songbo Liao</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Songbo Liao</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	

		<script type="text/javascript">
		_hcwp = window._hcwp || [];

		_hcwp.push({widget:"Bloggerstream", widget_id: 88976, selector:".hc-comment-count", label: "{\%COUNT%\}" });

		

		(function() {
		if("HC_LOAD_INIT" in window)return;
		HC_LOAD_INIT = true;
		var lang = (navigator.language || navigator.systemLanguage || navigator.userLanguage || "en").substr(0, 2).toLowerCase();
		var hcc = document.createElement("script"); hcc.type = "text/javascript"; hcc.async = true;
		hcc.src = ("https:" == document.location.protocol ? "https" : "http")+"://w.hypercomments.com/widget/hc/88976/"+lang+"/widget.js";
		var s = document.getElementsByTagName("script")[0];
		s.parentNode.insertBefore(hcc, s.nextSibling);
		})();
		</script>

	












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("EwzvCsk0iRkVjhwCjGf8OlG4-gzGzoHsz", "oT97Xq5wdUzBRRWG788ysT9n");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

</body>
</html>
